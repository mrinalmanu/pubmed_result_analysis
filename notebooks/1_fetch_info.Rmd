---
title: "part 1: preparing a list of papers"
author: "Mrinal Vashisth"
date: "3/8/2020"
output: html_document
---

```{r setup, include=FALSE}
#install.packages("easyPubMed")
library('easyPubMed')

```

```{r}

## Uncomment this cell to run contents

# my_query <- '((digital twin) AND ("2011/03/12"[PDat] : "2021/03/08"[PDat])))'
# 
# out.B <- batch_pubmed_download(pubmed_query_string = my_query, 
#                                dest_file_prefix = "DIG_T", 
#                                encoding = "ASCII")
# 
# head(out.B)
```

```{r}
# SOURCE: https://github.com/christopherBelter/pubmedXML/blob/master/pubmedXML.R
library(jsonlite)
library(purrr)
library(data.table)
library(stringr)
library(XML)
	
# modified march 9, 2021, mrinal vashisth, mrinalmanu10@gmail.com
# better handling of author names

## clean pubmed XML returned from either the reutils or rentrez packages and save the cleaned XML to a new file
clean_api_xml <- function(infile, outfile) {
	theData <- readChar(infile, file.info(infile)$size, useBytes = TRUE)
	theData <- gsub("<?xml version=\"1.0\" ?>", "", theData, fixed = TRUE)
	theData <- gsub("<!DOCTYPE PubmedArticleSet PUBLIC \"-//NLM//DTD PubMedArticle, 1st January 2019//EN\" \"https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_190101.dtd\">", "", theData, fixed = TRUE, useBytes = TRUE)
	theData <- gsub("<PubmedArticleSet>", "", theData, fixed = TRUE)
	theData <- gsub("</PubmedArticleSet>", "", theData, fixed = TRUE)
	theData <- gsub("<U\\+\\w{4}>", "", theData) ## note: with some files this doesn't catch everything; potial issue with <OtherAbstract> tags especially
	theData <- paste("<?xml version=\"1.0\" ?>", "<!DOCTYPE PubmedArticleSet PUBLIC \"-//NLM//DTD PubMedArticle, 1st January 2019//EN\" \"https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_190101.dtd\">", "<PubmedArticleSet>", theData, "</PubmedArticleSet>", sep = "\n")
	#theData <- paste(theData, "</PubmedArticleSet>")
	theData <- iconv(theData, to = "UTF-8", sub = "")
	writeLines(theData, outfile, sep = " ")
	return(theData)
}

## extract a data frame from the cleaned XML
## Note: does not handle <pubmedBookArticle> documents
extract_xml <- function(theFile) {

	newData <- xmlParse(theFile)
	records <- getNodeSet(newData, "//PubmedArticle")
	pmid <- xpathSApply(newData,"//MedlineCitation/PMID", xmlValue)
	doi <- lapply(records, xpathSApply, ".//ELocationID[@EIdType = \"doi\"]", xmlValue)
	doi[sapply(doi, is.list)] <- NA
	doi <- unlist(doi)
	
	#get complete author info instead
# pmid check to ensure that the information is accurate and complete
	
forename <- lapply(records, xpathSApply, ".//Author/ForeName", xmlValue)
lastname <- lapply(records, xpathSApply, ".//Author/LastName", xmlValue)
pmid <- xpathSApply(newData,"//MedlineCitation/PMID", xmlValue)

affiliation <- lapply(records, xpathSApply, ".//Author/AffiliationInfo", xmlValue)

new_x <- Map(list,forename, lastname, affiliation, pmid)

dt_list <- map(new_x, as.data.table)

dt <- rbindlist(dt_list, fill = TRUE, idcol = T)

new_dt <- data.frame(dt$V4, dt$.id, paste(paste(dt$V1, ' ', dt$V2, ' ','|', ' ', dt$V3)))

dt_x <- data.table(new_dt)
colnames(dt_x) <- c('pmid', 'id', 'author_info')

dt_final <- dt_x[, lapply(.SD, paste0, collapse=";"), by=pmid]
#dt_final$id <- gsub(";", "+", dt_final$id)
dt_final$number.of.a <- str_count(dt_final$id, ";") + 1


colnames(dt_final) <- c('pmid', 'id', 'author_info', 'number_of_authors')

dt_final$id <- NULL

# 	authLast <- lapply(records, xpathSApply, ".//Author/LastName", xmlValue)
# 	authLast[sapply(authLast, is.list)] <- NA
# 	authInit <- lapply(records, xpathSApply, ".//Author/Initials", xmlValue)
# 	authInit[sapply(authInit, is.list)] <- NA
# 	authors <- mapply(paste, authLast, authInit, collapse = "|")
# 	affiliations <- lapply(records, xpathSApply, ".//Author/AffiliationInfo/Affiliation", xmlValue)
#   affiliations[sapply(affiliations, is.list)] <- NA
# 	affiliations <- sapply(affiliations, paste, collapse = "|")

	year <- lapply(records, xpathSApply, ".//PubDate/Year", xmlValue) 
	year[sapply(year, is.list)] <- NA
	year[which(sapply(year, is.na) == TRUE)] <- lapply(records[which(sapply(year, is.na) == TRUE)], xpathSApply, ".//PubDate/MedlineDate", xmlValue)
	year <- gsub(" .+", "", year)
	year <- gsub("-.+", "", year)
	articletitle <- lapply(records, xpathSApply, ".//ArticleTitle", xmlValue) 
	articletitle[sapply(articletitle, is.list)] <- NA
	articletitle <- unlist(articletitle)
	journal <- lapply(records, xpathSApply, ".//ISOAbbreviation", xmlValue) 
	journal[sapply(journal, is.list)] <- NA
	journal <- unlist(journal)
	volume <- lapply(records, xpathSApply, ".//JournalIssue/Volume", xmlValue)
	volume[sapply(volume, is.list)] <- NA
	volume <- unlist(volume)
	issue <- lapply(records, xpathSApply, ".//JournalIssue/Issue", xmlValue)
	issue[sapply(issue, is.list)] <- NA
	issue <- unlist(issue)
	pages <- lapply(records, xpathSApply, ".//MedlinePgn", xmlValue)
	pages[sapply(pages, is.list)] <- NA
	pages <- unlist(pages)
	abstract <- lapply(records, xpathSApply, ".//Abstract/AbstractText", xmlValue)
	abstract[sapply(abstract, is.list)] <- NA
	abstract <- sapply(abstract, paste, collapse = "|")
	meshHeadings <- lapply(records, xpathSApply, ".//DescriptorName", xmlValue)
	meshHeadings[sapply(meshHeadings, is.list)] <- NA
	meshHeadings <- sapply(meshHeadings, paste, collapse = "|")
	chemNames <- lapply(records, xpathSApply, ".//NameOfSubstance", xmlValue)
	chemNames[sapply(chemNames, is.list)] <- NA
	chemNames <- sapply(chemNames, paste, collapse = "|")
	grantAgency <- lapply(records, xpathSApply, ".//Grant/Agency", xmlValue)
	grantAgency[sapply(grantAgency, is.list)] <- NA
	grantAgency <- sapply(grantAgency, paste, collapse = "|")
	grantAgency <- sapply(strsplit(grantAgency, "|", fixed = TRUE), unique)
	grantAgency <- sapply(grantAgency, paste, collapse = "|")
	names(grantAgency) <- NULL
	grantNumber <- lapply(records, xpathSApply, ".//Grant/GrantID", xmlValue)
	grantNumber[sapply(grantNumber, is.list)] <- NA
	grantNumber <- sapply(grantNumber, paste, collapse = "|")
	grantCountry <- lapply(records, xpathSApply, ".//Grant/Country", xmlValue)
	grantCountry[sapply(grantCountry, is.list)] <- NA
	grantCountry <- sapply(grantCountry, paste, collapse = "|")
	grantCountry <- sapply(strsplit(grantCountry, "|", fixed = TRUE), unique)
	grantCountry <- sapply(grantCountry, paste, collapse = "|")
	nctID <- lapply(records, xpathSApply, ".//DataBank[DataBankName = 'ClinicalTrials.gov']/AccessionNumberList/AccessionNumber", xmlValue)
	nctID[sapply(nctID, is.null)] <- NA
	nctID <- sapply(nctID, paste, collapse = "|")
	ptype <- lapply(records, xpathSApply, ".//PublicationType", xmlValue)
	ptype[sapply(ptype, is.list)] <- NA
	ptype <- sapply(ptype, paste, collapse = "|")
	
	# corrected here as well
	# corrected here as well
	theDF <- data.frame(pmid, doi, year, articletitle, journal, abstract, stringsAsFactors = FALSE)
	X_DF <- merge(x=dt_final, y=theDF, by=c("pmid")) # NA's match

	return(X_DF)
}



```
```{bash}
pwd
ls

```
```{r}
# mass extract XML
theData1 <- extract_xml('/home/mrinalmanu/Desktop/analyse_pubmed_search_results/FINAL/topics/virtual_twin/DIG_T01.txt')

theData <- do.call(rbind, list(theData1))

finalDF <- data.frame(theData$pmid, theData$doi, theData$year, theData$auth, theData$number_of_authors, theData$journal, theData$articletitle, theData$abstract)

#View(theData)

names(finalDF) <- c("pmid", "doi", "year", "author_info", "number_of_authors", "journal", "title", "abstract")

write.csv(finalDF, file = "DIG_T_DF", row.names = FALSE)

```

